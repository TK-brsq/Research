{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mHA80rTjPKzH",
        "9ncaaIgoVmnw",
        "imIg0hJyzo8f"
      ],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMBrHGFRVkf2+xR+OmPlf+q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TK-brsq/Research/blob/main/SimCLR2_by_SEW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzgLck_XNHmI",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d2cdc9-30b5-456b-f8dc-aae6a2a421fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spikingjelly\n",
            "  Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (2.5.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (4.66.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (0.20.0+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spikingjelly) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->spikingjelly) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->spikingjelly) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->spikingjelly) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->spikingjelly) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->spikingjelly) (3.0.2)\n",
            "Downloading spikingjelly-0.0.0.0.14-py3-none-any.whl (437 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/437.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m430.1/437.6 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.6/437.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: spikingjelly\n",
            "Successfully installed spikingjelly-0.0.0.0.14\n"
          ]
        }
      ],
      "source": [
        "#!pip uninstall -y tensorflow\n",
        "#!pip install tensorflow-cpu\n",
        "#!pip install tensorflow\n",
        "!pip install spikingjelly\n",
        "#!pip install wandb\n",
        "#!pip install torch_xla"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler as lrs\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torchvision.transforms import v2 as TF\n",
        "from torchvision import datasets\n",
        "\n",
        "import spikingjelly\n",
        "from spikingjelly.activation_based import layer as jnn, neuron, functional as jF\n",
        "\n",
        "from tqdm import tqdm\n",
        "import wandb"
      ],
      "metadata": {
        "id": "inE61C2fOS4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "mHA80rTjPKzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, inplane, outplane, down_sampling=True):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.down_sampling = down_sampling\n",
        "        self.stride = 2 if down_sampling else 1\n",
        "        self.down_sample  = nn.Sequential(\n",
        "            jnn.Conv2d(inplane, outplane, 2, 2, bias=False),\n",
        "            jnn.BatchNorm2d(outplane),\n",
        "            neuron.IFNode()\n",
        "        )\n",
        "\n",
        "        layer = []\n",
        "        layer.append(jnn.Conv2d(inplane, outplane, 3, self.stride, 1, 1, 2, bias=False))\n",
        "        layer.append(jnn.BatchNorm2d(outplane))\n",
        "        layer.append(neuron.IFNode())\n",
        "        layer.append(jnn.Conv2d(outplane, outplane, 3, 1, 1, 1, 2, bias=False))\n",
        "        layer.append(jnn.BatchNorm2d(outplane))\n",
        "        layer.append(neuron.IFNode())\n",
        "        self.layer = nn.Sequential(*layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.layer(x)\n",
        "        if self.down_sampling:\n",
        "            identity = self.down_sample(identity)\n",
        "        x += identity\n",
        "        return x\n",
        "\n",
        "class SEW_ResNet(nn.Module):\n",
        "    def __init__(self, T=4):\n",
        "        super(SEW_ResNet, self).__init__()\n",
        "        self.T = T\n",
        "\n",
        "        self.first = nn.Sequential(\n",
        "            jnn.Conv2d(3, 32, 3, 1, 1, bias=False),\n",
        "            jnn.BatchNorm2d(32),\n",
        "            neuron.IFNode()\n",
        "        )\n",
        "        self.block1 = BasicBlock(32, 32, False)\n",
        "        self.block2 = BasicBlock(32, 32, False)\n",
        "        self.block3 = BasicBlock(32, 64, True)\n",
        "        self.block4 = BasicBlock(64, 64, False)\n",
        "        self.block5 = BasicBlock(64, 128, True)\n",
        "        self.block6 = BasicBlock(128, 128, False)\n",
        "        self.last = nn.Sequential(\n",
        "            jnn.AdaptiveAvgPool2d((1, 1)),\n",
        "            jnn.Flatten()\n",
        "        )\n",
        "\n",
        "        jF.set_step_mode(self, 'm')\n",
        "\n",
        "    def forward(self, x):\n",
        "        jF.reset_net(self)\n",
        "        x = x.unsqueeze(0).repeat(self.T, 1, 1, 1, 1)\n",
        "        x = self.first(x)\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        #print(f'block6:{x[:,0,0,:4,:4]}')\n",
        "        x = self.last(x)\n",
        "        #print(f'last:{x[:,0,:8]}')\n",
        "        return x"
      ],
      "metadata": {
        "id": "_8s8xpOlPN9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Projector(nn.Module):\n",
        "    def __init__(self, indim=128, outdim=64):\n",
        "        super(Projector, self).__init__()\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(indim, outdim, bias=False)\n",
        "        )\n",
        "        #layer0 = self.projector[0]\n",
        "        #nn.init.normal_(layer0.weight, 1/128, 1/128**0.5)\n",
        "        #jF.set_step_mode(self, 'm')\n",
        "\n",
        "    def forward(self, h):\n",
        "        #jF.reset_net(self)\n",
        "        z = self.projector(h)\n",
        "        #print(f'z:{z[:,0,:8]}')\n",
        "        return z"
      ],
      "metadata": {
        "id": "qtm3rP_W5Kdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, encoder, projector):\n",
        "        super(SimCLR, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.projector = projector\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        h1, h2 = self.encoder(x1), self.encoder(x2)\n",
        "        h1, h2 = h1.mean(0), h2.mean(0)\n",
        "        z1, z2 = self.projector(h1), self.projector(h2)\n",
        "        return z1, z2"
      ],
      "metadata": {
        "id": "ELiZmzyxZhjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, indim, classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            jnn.Linear(indim, classes, bias=False),\n",
        "            neuron.IFNode()\n",
        "        )\n",
        "        jF.set_step_mode(self, 'm')\n",
        "    def forward(self, x):\n",
        "        jF.reset_net(self)\n",
        "        y = self.layer(x)\n",
        "        return y.mean(0)"
      ],
      "metadata": {
        "id": "kGhgK9xRkwxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NT_Xent(nn.Module):\n",
        "    def __init__(self, batch_size, tau, device):\n",
        "        super(NT_Xent, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.tau = tau\n",
        "        self.device = device\n",
        "        self.mask = self.make_mask()\n",
        "        self.cosine = nn.CosineSimilarity(dim=2)\n",
        "        self.Xent = nn.CrossEntropyLoss()\n",
        "\n",
        "    def make_mask(self):\n",
        "        mask = torch.eye(2 * self.batch_size, dtype=torch.bool)\n",
        "        ones = torch.ones(self.batch_size, dtype=torch.bool)\n",
        "        mask += torch.diag(ones, self.batch_size) + torch.diag(ones, -self.batch_size)\n",
        "        return ~mask\n",
        "\n",
        "    def forward(self, z1, z2):\n",
        "        z = torch.cat((z1, z2), dim=0).to(self.device)\n",
        "        similarity = self.cosine(z.unsqueeze(1), z.unsqueeze(0)) / self.tau\n",
        "\n",
        "        sim_ij = similarity[range(self.batch_size), range(self.batch_size, 2 * self.batch_size)]\n",
        "        sim_ji = similarity[range(self.batch_size, 2 * self.batch_size), range(self.batch_size)]\n",
        "\n",
        "        positive = torch.cat([sim_ij, sim_ji], dim=0).reshape(2*self.batch_size, 1)\n",
        "        negative = similarity[self.mask].reshape(2*self.batch_size, -1)\n",
        "\n",
        "        labels = torch.zeros(2*self.batch_size, dtype=torch.long).to(self.device)\n",
        "        logits = torch.cat((positive, negative), dim=1)\n",
        "        loss = self.Xent(logits, labels)\n",
        "\n",
        "        return loss / 2"
      ],
      "metadata": {
        "id": "tjhg4XyRPaaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "9ncaaIgoVmnw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataAugmentation:\n",
        "    def __init__(self):\n",
        "        color_jitter = TF.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
        "        self.tf = TF.Compose([\n",
        "            TF.RandomResizedCrop(32, (0.36, 1)),\n",
        "            TF.RandomHorizontalFlip(p=0.5),\n",
        "            TF.RandomApply([color_jitter], p=0.8),\n",
        "            TF.RandomGrayscale(p=0.2),\n",
        "            TF.ToImage(),\n",
        "            TF.ToDtype(torch.float32, scale=True)\n",
        "        ])\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.tf(x), self.tf(x)"
      ],
      "metadata": {
        "id": "c1QjfoDk1DX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(data='cifar10', split='train', batch_size=128, DA=False):\n",
        "    tf = DataAugmentation() if DA else TF.Compose([TF.ToImage(), TF.ToDtype(torch.float32, scale=True)])\n",
        "    if data == 'cifar10':\n",
        "        match split:\n",
        "            case 'train':\n",
        "                data = datasets.CIFAR10('./data', train=True, transform=tf, download=True)\n",
        "            case 'test':\n",
        "                data = datasets.CIFAR10('./data', train=False, transform=tf, download=True)\n",
        "            case 'all':\n",
        "                train = datasets.CIFAR10('./data', train=True, transform=tf, download=True)\n",
        "                test = datasets.CIFAR10('./data', train=False, transform=tf, download=True)\n",
        "                data = ConcatDataset([train, test])\n",
        "    elif data == 'stl10':\n",
        "        match split:\n",
        "            case 'train':\n",
        "                data = datasets.STL10('./data', split='train', transform=tf, download=True)\n",
        "            case 'test':\n",
        "                data = datasets.STL10('./data', split='test', transform=tf, download=True)\n",
        "            case 'all':\n",
        "                data = datasets.STL10('./data', split='unlabeled', transform=tf, download=True)\n",
        "    else:\n",
        "        print(f'{data} is not supported >_<. cifar10 or stl10 is supported')\n",
        "    loader = DataLoader(data, batch_size, shuffle=True, drop_last=True, num_workers=2)\n",
        "    return loader"
      ],
      "metadata": {
        "id": "uMIXsB32yVvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_(loader, model, optimizer, scheduler, criterion, device):\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    model.train()\n",
        "    for data, target in tqdm(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        correct += (out.argmax(1) == target).sum().item()\n",
        "    scheduler.step()\n",
        "    return running_loss, correct"
      ],
      "metadata": {
        "id": "QCe3SHrhaGUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_onTPU(loader, model, optimizer, scheduler, criterion, device):\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    model.train()\n",
        "    loader = pl.ParallelLoader(loader, [device]).per_device_loader(device)\n",
        "    for data, target in tqdm(loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(xm.xla_device()):\n",
        "            out = model(data)\n",
        "            loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        xm.optimizer_step(optimizer)\n",
        "        xm.mark_step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        correct += (out.argmax(1) == target).sum().item()\n",
        "    scheduler.step()\n",
        "    return running_loss, correct"
      ],
      "metadata": {
        "id": "4UpThriKV72x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cl(loader, model, optimizer, scheduler, criterion, device):\n",
        "    running_loss = 0\n",
        "    model.train()\n",
        "    for (x1, x2), _ in tqdm(loader):\n",
        "        x1, x2 = x1.to(device), x2.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        z1, z2 = model(x1, x2)\n",
        "        loss = criterion(z1, z2)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    scheduler.step()\n",
        "    return running_loss"
      ],
      "metadata": {
        "id": "g4lcasnwVpqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cl_onTPU(loader, model, optimizer, scheduler, criterion, device):\n",
        "    running_loss = 0\n",
        "    model.train()\n",
        "    loader = pl.ParallelLoader(loader, [device]).per_device_loader(device)\n",
        "    for (x1, x2), _ in tqdm(loader):\n",
        "        x1, x2 = x1.to(device), x2.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(xm.xla_device()):\n",
        "            z1, z2 = model(x1, x2)\n",
        "            loss = criterion(z1, z2)\n",
        "        loss.backward()\n",
        "        xm.optimizer_step(optimizer)\n",
        "        xm.mark_step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    scheduler.step()\n",
        "    return running_loss"
      ],
      "metadata": {
        "id": "i5N_OV5aWJT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_in_cl(loader, encoder, classifier, optimizer, criterion, device):\n",
        "    correct = 0\n",
        "    encoder.eval()\n",
        "    classifier.train()\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            z = encoder(data)\n",
        "        out = classifier(z)\n",
        "        loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct += (out.argmax(1) == target).sum().item()\n",
        "    return correct"
      ],
      "metadata": {
        "id": "9t9Ow04Q4kZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_in_cl_onTPU(loader, encoder, classifier, optimizer, criterion, device):\n",
        "    correct = 0\n",
        "    encoder.eval()\n",
        "    classifier.train()\n",
        "    loader = pl.ParallelLoader(loader, [device]).per_device_loader(device)\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(xm.xla_device()):\n",
        "            with torch.no_grad():\n",
        "                z = encoder(data)\n",
        "            out = classifier(z)\n",
        "            loss = criterion(out, target)\n",
        "        loss.backward()\n",
        "        xm.optimizer_step(optimizer)\n",
        "        xm.mark_step()\n",
        "\n",
        "        correct += (out.argmax(1) == target).sum().item()\n",
        "    return correct"
      ],
      "metadata": {
        "id": "zBPxpQPdWotX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(filename, model, optimizer, scheduler):\n",
        "    checkpoint = {\n",
        "        'model_sd': model.state_dict(),\n",
        "        'optimizer_sd': optimizer.state_dict(),\n",
        "        'scheduler_sd': scheduler.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, f'{filename}.pth')\n",
        "\n",
        "def load_checkpoint(filename, model, optimizer, scheduler):\n",
        "    checkpoint = torch.load(f'{filename}.pth')\n",
        "    model.load_state_dict(checkpoint['model_sd'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_sd'])\n",
        "    scheduler.load_state_dict(checkpoint['scheduler_sd'])"
      ],
      "metadata": {
        "id": "AQ-911kihgC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "sv6z2_DA_3Ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#instance\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = torch_xla.device()\n",
        "#------------------------#\n",
        "loader = get_loader('cifar10', split='all', batch_size=256, DA=True)\n",
        "loader2 = get_loader('cifar10', split='test', batch_size=128, DA=False)\n",
        "N = len(loader2.dataset)\n",
        "#------------------------#\n",
        "encoder = SEW_ResNet(4)\n",
        "projector = Projector()\n",
        "model = SimCLR(encoder, projector).to(device)\n",
        "classifier = Classifier(128, 10).to(device)\n",
        "#------------------------#\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.6, momentum=0.9)\n",
        "optimizer2 = optim.Adam(classifier.parameters())\n",
        "scheduler1 = lrs.LinearLR(optimizer, 1, 0.5, 4)\n",
        "#scheduler2 = lrs.CosineAnnealingLR(optimizer, 15, 0.1)\n",
        "#scheduler = lrs.ChainedScheduler([scheduler1, scheduler2], optimizer)\n",
        "#------------------------#\n",
        "criterion = NT_Xent(256, 0.2, device).to(device)\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "\n",
        "wandb.login()\n",
        "run = wandb.init(\n",
        "    project = 'SimCLR SEW 1102',\n",
        "    config = {\n",
        "        'Architecture': 'SEWResNet14',\n",
        "        'projector': 'ANN1layer',\n",
        "        'feature dim': 128,\n",
        "        'embedding dim': 64,\n",
        "        'T': 4,\n",
        "        'optim': 'SGD',\n",
        "        'momentum': 0.9,\n",
        "        'lr': 0.6,\n",
        "        'sche1': 'Linear(1, 0.5, 4)',\n",
        "        'sche2': 'None',\n",
        "        'sche': 'None',\n",
        "        'change sche': 'None',\n",
        "        'criterion': 'NT-Xent',\n",
        "        'tau': 0.2,\n",
        "        'Data': 'Cifar10',\n",
        "        'batch': 256,\n",
        "        'else': 'groups=2, down_sample.stride=2, ADD'\n",
        "    }\n",
        ")\n",
        "\n",
        "#train\n",
        "start_epoch = 0\n",
        "epochs = 32\n",
        "for epoch in range(start_epoch, epochs):\n",
        "    loss = train_cl(loader, model, optimizer, scheduler1, criterion, device)\n",
        "    correct = train_in_cl(loader2, model.encoder, classifier, optimizer2, criterion2, device)\n",
        "    wandb.log({'loss': loss, 'acc': correct*100/N})\n",
        "    print(f'Epoch: {epoch} | loss: {loss} | acc: {correct*100/N}%')\n",
        "\n",
        "wandb.finish()\n",
        "save_checkpoint('SimCLR_by_SEW_1110_ADD_3', model, optimizer, scheduler1)"
      ],
      "metadata": {
        "id": "v-dkMx6Y_7Em",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87613473-ea45-4689-dcb5-5f08fc262c42",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 41.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtk-0311-h\u001b[0m (\u001b[33mtk-0311-h-hosei-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241110_064240-4dml6ds6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102/runs/4dml6ds6' target=\"_blank\">fragrant-forest-15</a></strong> to <a href='https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102' target=\"_blank\">https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102/runs/4dml6ds6' target=\"_blank\">https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102/runs/4dml6ds6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:12<00:00,  1.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | loss: 702.6946165561676 | acc: 20.96%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | loss: 634.743766784668 | acc: 19.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 | loss: 535.2988519668579 | acc: 25.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 | loss: 477.702418923378 | acc: 27.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 | loss: 442.0260227918625 | acc: 29.98%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 | loss: 425.7961231470108 | acc: 30.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 | loss: 413.22518742084503 | acc: 33.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 | loss: 403.3268154859543 | acc: 33.67%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 | loss: 394.5040558576584 | acc: 36.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 | loss: 388.5546405315399 | acc: 37.12%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 | loss: 383.49152982234955 | acc: 37.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11 | loss: 378.68061113357544 | acc: 38.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12 | loss: 375.6810508966446 | acc: 40.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 | loss: 372.57968175411224 | acc: 39.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14 | loss: 368.9892827272415 | acc: 40.6%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15 | loss: 366.4579008817673 | acc: 41.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16 | loss: 364.2126432657242 | acc: 41.72%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17 | loss: 361.8333238363266 | acc: 42.46%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18 | loss: 360.60885059833527 | acc: 42.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19 | loss: 358.78042018413544 | acc: 42.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20 | loss: 356.40119230747223 | acc: 43.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21 | loss: 355.54558634757996 | acc: 44.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22 | loss: 354.7785128355026 | acc: 43.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23 | loss: 353.0196750164032 | acc: 43.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24 | loss: 352.4152147769928 | acc: 44.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25 | loss: 350.8228083848953 | acc: 44.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26 | loss: 350.75747632980347 | acc: 44.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27 | loss: 349.05703341960907 | acc: 45.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28 | loss: 348.6615844964981 | acc: 45.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29 | loss: 347.6818438768387 | acc: 44.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30 | loss: 346.4684873819351 | acc: 45.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 234/234 [03:09<00:00,  1.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31 | loss: 346.2931708097458 | acc: 44.85%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▁▂▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇▇████████</td></tr><tr><td>loss</td><td>█▇▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>44.85</td></tr><tr><td>loss</td><td>346.29317</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fragrant-forest-15</strong> at: <a href='https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102/runs/4dml6ds6' target=\"_blank\">https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102/runs/4dml6ds6</a><br/> View project at: <a href='https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102' target=\"_blank\">https://wandb.ai/tk-0311-h-hosei-university/SimCLR%20SEW%201102</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241110_064240-4dml6ds6/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11/10**\n",
        "\n",
        "encoder : SEW ResNet13, group=2, down_sample.stride=2\n",
        "\n",
        "projector : 1layer ANN\n",
        "\n",
        "optimizer : SGD, lr=1\n",
        "\n",
        "scheduler : Linear(1->0.3) + Cosine(0.3->0.1)\n",
        "\n",
        "Else : T=4, batch=256\n",
        "\n",
        "enviroment : L4 GPU, 3min/epoch, 12.1/22 GB\n",
        "\n",
        "-> smooth leaf 13"
      ],
      "metadata": {
        "id": "HyFYyfhNYiCu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspection"
      ],
      "metadata": {
        "id": "imIg0hJyzo8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = get_loader('cifar10', split='test', batch_size=64, DA=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU3WJOVr_Bud",
        "outputId": "4ed74835-dad1-4ef6-b94b-07fce56d37fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 47.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis\n",
        "device = torch.device('cpu')\n",
        "e = SEW_ResNet(4)\n",
        "p = Projector()\n",
        "m = SimCLR(e, p)\n",
        "cl = Classifier(128, 10)\n",
        "cr = NT_Xent(64, 0.2, device)\n",
        "#load state dict\n",
        "#cp = torch.load('SimCLR_by_SEW_1109_ADD.pth', weights_only=True, map_location=device)\n",
        "#m.load_state_dict(cp['model_sd'])\n",
        "\n",
        "(d1, d2), t = next(iter(l))\n",
        "z1, z2 = m(d1, d2)\n",
        "loss = cr(z1, z2)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "pl0Sd-zZSQMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a1aae0-483b-43f4-e6e2-289fa2f9ab85",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4113, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Result\n",
        "# T4 | 13.2 / 15 GB | batch=512, T=2 | 2m / epoch | 1epで10%, 2epで14%\n",
        "# L4 | 28.9 / 22 GB | same | 1epで14%\n",
        "# TPU | diagでエラー | positiveのdiagをno_grad()の中に だめ -> loaderをparallel_loaderへ(T=1) 1.5min/epochできた\n",
        "# TPU | 上のままTを上げていく T=2でダメ -> mixed precision で T=2 OK, 2min/epoch\n",
        "# 上の記録 | 13.23 -> 16.35 -> 18.44 -> 19.58 -> 19.96 -> 21.24 > 21.53 > 21.8\n",
        "\n",
        "# down_sampleのstride=2, groups=2でやろう. paramsが1200k->500k\n",
        "# T4 GPU | batch=256, T=3(9.8GB) OK(13%) | T=4(12.7GB) できる(13%) | T=5は無理そう\n",
        "# TPU | batch=256, T=1 OK(10.4%) | T=2 OK(12.2%) | T=3 OK(13.2%) | T=4 NO(Exhausted)\n",
        "# ひとまず TPU N=256, T=3, epochs=32, 20%でsaturation\n",
        "# projectorをANNに変えたらResorce Exhausted\n",
        "# L4 GPU | N=256 T=4 epochs=16 | 3min/epoch -> epoch5 17%でsaturation | z1, z2は異常なし\n",
        "\n",
        "# 11/7 z1,z2問題解決\n",
        "# hyper parameterは上と同じ | L4 GPUで3.1min/epoch | RAMは半分 -> まだいけるぞ |\n",
        "# 34%まではうまくいった -> lrが小さすぎて坂を上れなかったか -> T-wiseでlossとる | どうであれもっとepoch増やしてから分析\n",
        "# 11/9 state dictをsaveしっかり | 最初の8epochまでは上と変えてないがloss, accともに異なる曲線に -> 不安定 -> やはりT-wiseにするしか?\n",
        "# 11/10\n",
        "# 保存しっかり"
      ],
      "metadata": {
        "id": "b-d8ffTYDcoQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}